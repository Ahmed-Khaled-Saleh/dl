"""All things Data (Processing, exploration, Visualization, augmentation, loading, etc)"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_data.ipynb.

# %% auto 0
__all__ = ['cl_labels', 'image_size', 'base_tf', 'transform', 'denormalize_tf', 'aug_train_tf', 'aug_test_tf',
           'RetinaMultiLabelDataset', 'get_cls', 'old_show_batch', 'show_batch', 'RetinaMultiLabelDatasetAug',
           'init_data', 'get_pos_counts']

# %% ../nbs/01_data.ipynb 3
from fastcore.utils import *
from fastcore import *

# %% ../nbs/01_data.ipynb 4
import os
import pandas as pd
from PIL import Image

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import v2

# %% ../nbs/01_data.ipynb 5
cl_labels = ["DR", "Glaucoma", "AMD"]

# %% ../nbs/01_data.ipynb 6
class RetinaMultiLabelDataset(Dataset):
    def __init__(self, csv_file, image_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.image_dir = image_dir
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data.iloc[idx]
        img_path = os.path.join(self.image_dir, row.iloc[0])
        img = Image.open(img_path).convert("RGB")
        labels = torch.tensor(row[1:].values.astype("float32"))
        if self.transform:
            img = self.transform(img)
        return img, labels


# %% ../nbs/01_data.ipynb 8
import importlib
def get_cls(module_name, class_name):
    module = importlib.import_module(module_name)
    return getattr(module, class_name)

# %% ../nbs/01_data.ipynb 9
import matplotlib.pyplot as plt
import numpy as np
import torchvision
import torch
def old_show_batch(dl, denormalize_tf, save_to= "./batch.png", aug= False):
    def imshow(img):
        npimg = img.numpy()
        plt.imshow(np.transpose(npimg, (1, 2, 0)))
        plt.savefig(save_to)
        plt.show()

    dataiter = iter(dl)
    images, labels = next(dataiter)
    if aug and images.dim() == 5:
        images = images.flatten(0, 1)
        labels = labels.flatten(0, 1)
        
    images = denormalize_tf(images)
    images = torch.clamp(images, 0, 1)
        
    indices = [torch.where(row == 1)[0].tolist() for row in labels]
    print('Labels: ',[[cl_labels[i] for i in idx] for idx in indices])
    imshow(torchvision.utils.make_grid(images))

# %% ../nbs/01_data.ipynb 10
import matplotlib.pyplot as plt
import numpy as np
import torchvision
import torch
def show_batch(dl, denormalize_tf, save_to="./batch.png", aug=False):
    dataiter = iter(dl)
    images, labels = next(dataiter)

    if aug and images.ndim == 5:
        images = images.flatten(0, 1)
        labels = labels.flatten(0, 1)
        
    images = denormalize_tf(images)
    print(f"Max pixel value: {images.max().item()}")
    print(f"Mean pixel value: {images.mean().item()}")
    images = torch.clamp(images, 0, 1)

    grid_img = torchvision.utils.make_grid(images, nrow=8) # nrow controls how many images per row
    np_grid = grid_img.permute(1, 2, 0).cpu().numpy()

    indices = [torch.where(row == 1)[0].tolist() for row in labels]
    batch_label_names = [[cl_labels[i] for i in idx] for idx in indices]
    print('Labels in this batch:', batch_label_names)

    plt.figure(figsize=(15, 10))
    plt.imshow(np_grid)
    plt.axis('off')
    plt.savefig(save_to, bbox_inches='tight')
    plt.savefig("pdf.pdf", bbox_inches='tight')
    plt.show()

# %% ../nbs/01_data.ipynb 13
image_size = 224
base_tf = transform = v2.Compose([
        v2.Resize((image_size, image_size)),
        v2.ToImage(),
        v2.ToDtype(torch.float32, scale=True),
        v2.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
    ])

denormalize_tf = v2.Normalize(
    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
    std=[1/0.229, 1/0.224, 1/0.225]
)

# %% ../nbs/01_data.ipynb 20
class RetinaMultiLabelDatasetAug(Dataset):
    def __init__(self, ds, transform=None, V=2):
        self.ds = ds
        self.V = V
        self.transform = transform

    def __len__(self):
        return len(self.ds)

    def __getitem__(self, idx):
        item = self.ds[idx]
        img = item[0]
        return torch.stack([self.transform(img) for _ in range(self.V)]), item[1]



# %% ../nbs/01_data.ipynb 21
image_size = 224
# aug_train_tf = v2.Compose([
#     # 1. Geometric & Color Augs (on PIL or Int Tensor)
#     v2.RandomResizedCrop(256, scale=(0.5, 1.0)),
#     v2.RandomHorizontalFlip(),
#     v2.RandomApply([v2.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8), # Dialed down from 0.8
    
#     v2.ToImage(),
#     v2.ToDtype(torch.float32, scale=True),
    
#     v2.RandomApply([v2.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0))], p=0.5),
#     v2.RandomApply([v2.RandomSolarize(threshold=0.8)], p=0.1), # Higher threshold = less dark
    
#     v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
# ])
aug_train_tf = v2.Compose([
    v2.Resize((image_size, image_size)), 
    
    # v2.RandomResizedCrop(image_size, scale=(0.9, 1.0), ratio=(0.95, 1.05)),
    
    # 3. Retinal images are rotationally symmetric
    # v2.RandomHorizontalFlip(p=0.5),
    # v2.RandomVerticalFlip(p=0.5),
    # v2.RandomRotation(degrees=180), # Full rotation is safe for eyes
    
    # # 4. Gentle lighting variation (Remove Solarize and Blur)
    # v2.RandomApply([
    #     v2.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.1)
    # ], p=0.3),
    
    v2.ToImage(),
    v2.ToDtype(torch.float32, scale=True),
    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

aug_test_tf = v2.Compose(
            [
                # v2.Resize(image_size),
                v2.Resize(int(image_size * 1.14), interpolation=v2.InterpolationMode.BICUBIC),
                v2.CenterCrop(image_size),
                v2.ToImage(),
                v2.ToDtype(torch.float32, scale=True),
                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ]
)

# %% ../nbs/01_data.ipynb 27
def init_data(cfg, transform=base_tf, num_workers=0):

    train_csv = os.path.join(cfg.data.data_root , "train.csv")
    train_image_dir = os.path.join(cfg.data.data_root , "images", "train")

    val_csv = os.path.join(cfg.data.data_root , "val.csv")
    val_image_dir =  os.path.join(cfg.data.data_root , "images", "val")
    
    test_csv = os.path.join(cfg.data.data_root , "offsite_test.csv")
    test_image_dir = os.path.join(cfg.data.data_root , "images", "offsite_test")

    ds_cls = get_cls("dl.data", "RetinaMultiLabelDataset")

    train_ds = ds_cls(train_csv, train_image_dir, transform)
    val_ds   = ds_cls(val_csv, val_image_dir, transform)
    test_ds  = ds_cls(test_csv, test_image_dir, transform)

    if cfg.data.name == "RetinaMultiLabelDatasetAug":    
        ds_cls = get_cls("dl.data", cfg.data.name)
        train_ds = ds_cls(train_ds, transform=aug_train_tf, V=cfg.data.V)
        val_ds = ds_cls(val_ds, transform=aug_test_tf, V=1)
        test_ds = ds_cls(test_ds, transform=aug_test_tf, V=1)
        

    train_loader = DataLoader(train_ds, batch_size=cfg.data.batch_size, shuffle=True, num_workers=num_workers)
    val_loader   = DataLoader(val_ds, batch_size=cfg.data.batch_size, shuffle=False, num_workers=num_workers)
    test_loader  = DataLoader(test_ds, batch_size=cfg.data.batch_size, shuffle=False, num_workers=num_workers)
    
    return train_loader, val_loader, test_loader

# %% ../nbs/01_data.ipynb 34
import torch

def get_pos_counts(dataloader):
    first_batch_labels = next(iter(dataloader))[1]
    num_classes = first_batch_labels.shape[1]
    pos_counts = torch.zeros(num_classes)

    print("Calculating class frequencies...")
    for _, labels in dataloader:
        pos_counts += labels.sum(dim=0)
    
    return pos_counts

