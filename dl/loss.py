"""Fill in a module description here"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_loss.ipynb.

# %% auto 0
__all__ = ['FocalLoss', 'focalLoss', 'get_cls', 'init_loss']

# %% ../nbs/03_loss.ipynb 3
def FocalLoss(): pass

# %% ../nbs/03_loss.ipynb 4
import torch
import torch.nn as nn
import torch.nn.functional as F


class focalLoss(nn.Module):
    def __init__(self, gamma=2, alpha=None):
        super(focalLoss, self).__init__()
        self.gamma = gamma
        self.alpha = alpha

    def forward(self, inputs, y):
        p = torch.sigmoid(inputs)

        bce_loss = F.binary_cross_entropy_with_logits(inputs, y, reduction='none')

        p_t = p * y + (1 - p) * (1 - y)
        focal_weight = (1 - p_t) ** self.gamma

    
        alpha_t = self.alpha * y + (1 - self.alpha) * (1 - y)
        bce_loss = alpha_t * bce_loss

        loss = focal_weight * bce_loss
        return loss.mean()

# %% ../nbs/03_loss.ipynb 5
import torch
import torch.nn as nn
import torch.nn.functional as F

class FocalLoss(nn.Module):
    def __init__(self, gamma=2, alpha=0.25):
        super(FocalLoss, self).__init__()
        self.gamma = gamma
        self.alpha = alpha

    def forward(self, inputs, targets):
        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')

        p_t = torch.exp(-bce_loss)
        focal_weight = (1 - p_t) ** self.gamma

        if self.alpha is not None:
            if isinstance(self.alpha, (float, int)):
                alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
            else:
                alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
            
            bce_loss = alpha_t * bce_loss

        loss = focal_weight * bce_loss
        
        return loss.mean()

# %% ../nbs/03_loss.ipynb 6
import importlib
def get_cls(module_name, class_name):
    module = importlib.import_module(module_name)
    return getattr(module, class_name)

# %% ../nbs/03_loss.ipynb 7
def init_loss(cfg):
    if cfg.loss.name == "BCEWithLogitsLoss":
        return torch.nn.BCEWithLogitsLoss()
    
    loss_cls = get_cls("dl.loss", cfg.loss.name)
    loss = loss_cls(**cfg.loss.params)
    return loss
